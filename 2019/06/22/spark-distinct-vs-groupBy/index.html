<!DOCTYPE html>
<html lang="zh-CN">
  <head>
    
<meta charset="UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>


<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />

<meta name="theme-color" content="#f8f5ec" />
<meta name="msapplication-navbutton-color" content="#f8f5ec">
<meta name="apple-mobile-web-app-capable" content="yes">
<meta name="apple-mobile-web-app-status-bar-style" content="#f8f5ec">



  <meta name="description" content="Spark distinct() vs. groupBy()"/>




  <meta name="keywords" content="数据处理, Spark, 源码分析, Lingering Fragments" />










  <link rel="alternate" href="/default" title="Lingering Fragments">




  <link rel="shortcut icon" type="image/x-icon" href="/favicon.ico?v=2.10.1" />



<link rel="canonical" href="https://pengye91.github.io/2019/06/22/spark-distinct-vs-groupBy/"/>



  <link rel="stylesheet" type="text/css" href="/lib/fancybox/jquery.fancybox.css" />




  <link rel="stylesheet" type="text/css" href="/lib/nprogress/nprogress.min.css" />



<link rel="stylesheet" type="text/css" href="/css/style.css?v=2.10.1" />



  


<!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-127442719-1"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'UA-127442719-1');
</script>


  <script id="baidu_push">
(function(){
    var bp = document.createElement('script');
    var curProtocol = window.location.protocol.split(':')[0];
    if (curProtocol === 'https') {
        bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';
    }
    else {
        bp.src = 'http://push.zhanzhang.baidu.com/push.js';
    }
    var s = document.getElementsByTagName("script")[0];
    s.parentNode.insertBefore(bp, s);
})();
</script>








<script>
  window.config = {"title":"Lingering Fragments","subtitle":"一些想法和总结","description":null,"author":"xyp","language":"zh-CN","timezone":"Asia/Shanghai","url":"https://pengye91.github.io","root":"/","permalink":":year/:month/:day/:title/","permalink_defaults":null,"source_dir":"source","public_dir":"public","tag_dir":"tags","archive_dir":"archives","category_dir":"categories","code_dir":"downloads/code","i18n_dir":":lang","skip_render":null,"new_post_name":":title.md","default_layout":"post","titlecase":false,"external_link":true,"filename_case":0,"render_drafts":false,"post_asset_folder":false,"relative_link":false,"future":true,"highlight":{"enable":true,"auto_detect":false,"line_number":true,"tab_replace":null,"first_line_number":"always1"},"default_category":"uncategorized","category_map":null,"tag_map":null,"date_format":"YYYY-MM-DD","time_format":"HH:mm:ss","per_page":10,"pagination_dir":"page","theme":"even","deploy":{"type":"git","repo":"https://github.com/pengye91/pengye91.github.io.git","branch":"master"},"ignore":[],"keywords":null,"index_generator":{"per_page":10,"order_by":"-date","path":""},"sitemap":{"path":"sitemap.xml"},"baidusitemap":{"path":"baidusitemap.xml"},"archive_generator":{"per_page":10,"yearly":true,"monthly":true,"daily":false},"category_generator":{"per_page":10},"tag_generator":{"per_page":10},"marked":{"gfm":true,"pedantic":false,"sanitize":false,"tables":true,"breaks":true,"smartLists":true,"smartypants":true,"modifyAnchors":"","autolink":true},"server":{"port":4000,"log":false,"compress":false,"header":true},"since":2018,"favicon":"/favicon.ico","rss":"default","menu":{"Home":"/","Archives":"/archives/","Tags":"/tags","Categories":"/categories","About":"/about"},"color":"cobalt blue","mode":"default","toc":true,"fancybox":true,"pjax":true,"copyright":{"enable":false,"license":"<a rel=\"license\" href=\"http://creativecommons.org/licenses/by-nc/4.0/\" target=\"_blank\">知识共享署名-非商业性使用 4.0 国际许可协议</a>"},"reward":{"enable":false,"qrCode":{"wechat":null,"alipay":null}},"social":{"email":"pengye91@gmail.com","stack-overflow":null,"twitter":null,"facebook":null,"linkedin":null,"google":null,"github":"https://github.com/pengye91","weibo":null,"zhihu":null,"douban":null,"pocket":null,"tumblr":null,"instagram":null},"leancloud":{"app_id":null,"app_key":null},"baidu_analytics":null,"baidu_verification":null,"google_analytics":"UA-127442719-1","google_verification":null,"disqus_shortname":null,"valine":{"appid":"xeDhasO1xV7F1SpCG0oRuiol-gzGzoHsz","appkey":"wgFvo2YMOmn0Qcv7YPFxtePy","notify":false,"verify":false,"avatar":"identicon","visitor":true,"placeholder":"在此评论......"},"changyan":{"appid":null,"appkey":null},"livere_datauid":null,"version":"2.10.1"};
</script>

    <title> Spark distinct() vs. groupBy() - Lingering Fragments </title>
  </head>

  <body><div id="mobile-navbar" class="mobile-navbar">
  <div class="mobile-header-logo">
    <a href="/." class="logo">Lingering Fragments</a>
  </div>
  <div class="mobile-navbar-icon">
    <span></span>
    <span></span>
    <span></span>
  </div>
</div>

<nav id="mobile-menu" class="mobile-menu slideout-menu">
  <ul class="mobile-menu-list">
    
      <a href="/">
        <li class="mobile-menu-item">
          
          
            首页
          
        </li>
      </a>
    
      <a href="/archives/">
        <li class="mobile-menu-item">
          
          
            归档
          
        </li>
      </a>
    
      <a href="/tags">
        <li class="mobile-menu-item">
          
          
            标签
          
        </li>
      </a>
    
      <a href="/categories">
        <li class="mobile-menu-item">
          
          
            分类
          
        </li>
      </a>
    
      <a href="/about">
        <li class="mobile-menu-item">
          
          
            关于
          
        </li>
      </a>
    
  </ul>
</nav>

    <div class="container" id="mobile-panel">
      <header id="header" class="header"><div class="logo-wrapper">
  <a href="/." class="logo">Lingering Fragments</a>
</div>

<nav class="site-navbar">
  
    <ul id="menu" class="menu">
      
        <li class="menu-item">
          <a class="menu-item-link" href="/">
            
            
              首页
            
          </a>
        </li>
      
        <li class="menu-item">
          <a class="menu-item-link" href="/archives/">
            
            
              归档
            
          </a>
        </li>
      
        <li class="menu-item">
          <a class="menu-item-link" href="/tags">
            
            
              标签
            
          </a>
        </li>
      
        <li class="menu-item">
          <a class="menu-item-link" href="/categories">
            
            
              分类
            
          </a>
        </li>
      
        <li class="menu-item">
          <a class="menu-item-link" href="/about">
            
            
              关于
            
          </a>
        </li>
      
    </ul>
  
</nav>

      </header>

      <main id="main" class="main">
        <div class="content-wrapper">
          <div id="content" class="content">
            
  
  <article class="post">
    <header class="post-header">
      <h1 class="post-title">
        
          Spark distinct() vs. groupBy()
        
      </h1>

      <div class="post-meta">
        <span class="post-time">
          2019-06-22
        </span>
        
          <span class="post-category">
            
              <a href="/categories/Spark/">Spark</a>
            
              <a href="/categories/Spark/源码阅读/">源码阅读</a>
            
              <a href="/categories/Spark/源码阅读/数据处理/">数据处理</a>
            
          </span>
        
        
      </div>
    </header>

    
    
  <div class="post-toc" id="post-toc">
    <h2 class="post-toc-title">文章目录</h2>
    <div class="post-toc-content">
      <ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#前言"><span class="toc-text">前言</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#方案一：使用-distinct"><span class="toc-text">方案一：使用 distinct()</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#分析一"><span class="toc-text">分析一</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#distinct"><span class="toc-text">distinct()</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#dropDuplicates"><span class="toc-text">dropDuplicates()</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#小结"><span class="toc-text">小结</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#方案二：使用-groupBy"><span class="toc-text">方案二：使用 groupBy()</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#分析二"><span class="toc-text">分析二</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#小结-1"><span class="toc-text">小结</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#初步结论"><span class="toc-text">初步结论</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#真的吗？"><span class="toc-text">真的吗？</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#总结"><span class="toc-text">总结</span></a></li></ol>
    </div>
  </div>



    <div class="post-content">
      
        <h1 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h1><p>最近在项目中遇到一个需求：</p>
<blockquote>
<p>数据需要按照某些维度分区存储在 S3 上，例如：<code>s3://bucket.name/field_1=a/field_2=b/field_3=c/xxxxx.parquet</code>。<br>另外，在公司系统中，元数据是手动管理，因此在对数据文件进行更改过程中，需要在写入前手动取出所有的分区字段对应的值。<br>先不论是否有更好地方式管理写入文件相应过程，我们考虑一下目前这个需求该怎样高效地实现。</p>
</blockquote>
<p>在这次讨论中，我们都只考虑 <code>Dataframe</code> 接口。</p>
<a id="more"></a>
<h1 id="方案一：使用-distinct"><a href="#方案一：使用-distinct" class="headerlink" title="方案一：使用 distinct()"></a>方案一：使用 <code>distinct()</code></h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">values = df.select(<span class="string">"field_1"</span>, <span class="string">"field_2"</span>, <span class="string">"field_3"</span>).distinct().collect()</span><br></pre></td></tr></table></figure>
<h1 id="分析一"><a href="#分析一" class="headerlink" title="分析一"></a>分析一</h1><h2 id="distinct"><a href="#distinct" class="headerlink" title="distinct()"></a><strong>distinct()</strong></h2><p>在 <code>Spark</code> 源码中：</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment">  * Returns a new Dataset that contains only the unique rows from this Dataset.</span></span><br><span class="line"><span class="comment">  * This is an alias for `dropDuplicates`.</span></span><br><span class="line"><span class="comment">  */</span></span><br><span class="line"> <span class="function"><span class="keyword">def</span> <span class="title">distinct</span></span>(): <span class="type">Dataset</span>[<span class="type">T</span>] = dropDuplicates()</span><br></pre></td></tr></table></figure>
<p><code>distinct()</code> 和 <code>dropDuplicates()</code> 是同一个接口。</p>
<h2 id="dropDuplicates"><a href="#dropDuplicates" class="headerlink" title="dropDuplicates()"></a>dropDuplicates()</h2><p>再看 <code>dropDuplicates()</code> 接口：</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">dropDuplicates</span></span>(): <span class="type">Dataset</span>[<span class="type">T</span>] = dropDuplicates(<span class="keyword">this</span>.columns)</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * (Scala-specific) Returns a new Dataset with duplicate rows removed, considering only</span></span><br><span class="line"><span class="comment"> * the subset of columns.</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">dropDuplicates</span></span>(colNames: <span class="type">Seq</span>[<span class="type">String</span>]): <span class="type">Dataset</span>[<span class="type">T</span>] = withTypedPlan &#123;</span><br><span class="line">  <span class="keyword">val</span> resolver = sparkSession.sessionState.analyzer.resolver</span><br><span class="line">  <span class="keyword">val</span> allColumns = queryExecution.analyzed.output</span><br><span class="line">  <span class="keyword">val</span> groupCols = colNames.toSet.toSeq.flatMap &#123; (colName: <span class="type">String</span>) =&gt;</span><br><span class="line">    <span class="comment">// It is possibly there are more than one columns with the same name,</span></span><br><span class="line">    <span class="comment">// so we call filter instead of find.</span></span><br><span class="line">    <span class="keyword">val</span> cols = allColumns.filter(col =&gt; resolver(col.name, colName))</span><br><span class="line">    <span class="keyword">if</span> (cols.isEmpty) &#123;</span><br><span class="line">      <span class="keyword">throw</span> <span class="keyword">new</span> <span class="type">AnalysisException</span>(</span><br><span class="line">        <span class="string">s""</span><span class="string">"Cannot resolve column name "</span>$colN<span class="string">ame" among (<span class="subst">$&#123;schema.fieldNames.mkString(", ")&#125;</span>)"</span><span class="string">""</span>)</span><br><span class="line">    &#125;</span><br><span class="line">    cols</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="type">Deduplicate</span>(groupCols, logicalPlan)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>在 <code>dropDuplicates</code> 中：</p>
<ul>
<li>首先检查需要被 <code>distinct</code> 的 <code>field</code> 是否被正常解析了。</li>
<li><p>返回一个 <code>case class</code>: <code>Deduplicate</code></p>
<ul>
<li><code>Deduplicate</code> 在 <code>org.apache.spark.sql.catalyst.plans.logical</code> package 下；</li>
<li><p>定义如下：</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">    <span class="comment">/** A logical plan for `dropDuplicates`. */</span></span><br><span class="line">    <span class="keyword">case</span> <span class="class"><span class="keyword">class</span> <span class="title">Deduplicate</span>(<span class="params"></span></span></span><br><span class="line"><span class="class"><span class="params">        keys: <span class="type">Seq</span>[<span class="type">Attribute</span>],</span></span></span><br><span class="line"><span class="class"><span class="params">        child: <span class="type">LogicalPlan</span></span>)</span></span><br><span class="line"><span class="class">    <span class="keyword">extends</span> <span class="title">UnaryNode</span> </span>&#123;</span><br><span class="line">      <span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">output</span></span>: <span class="type">Seq</span>[<span class="type">Attribute</span>] = child.output</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
</li>
<li><p>可以发现，这是一个逻辑执行计划的操作符，用于将 SQL 语句或者 <code>DataSet</code> API 中的 <code>DISTINCT</code> 关键字和接口转换为 <code>Deduplicate</code> 操作符。</p>
</li>
</ul>
</li>
</ul>
<p>接下来可以看这个操作符在 SQL 优化器中被用到:</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * Replaces logical [[Deduplicate]] operator with an [[Aggregate]] operator.</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">ReplaceDeduplicateWithAggregate</span> <span class="keyword">extends</span> <span class="title">Rule</span>[<span class="type">LogicalPlan</span>] </span>&#123;</span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">apply</span></span>(plan: <span class="type">LogicalPlan</span>): <span class="type">LogicalPlan</span> = plan transform &#123;</span><br><span class="line">    <span class="keyword">case</span> <span class="type">Deduplicate</span>(keys, child) <span class="keyword">if</span> !child.isStreaming =&gt;</span><br><span class="line">      <span class="keyword">val</span> keyExprIds = keys.map(_.exprId)</span><br><span class="line">      <span class="keyword">val</span> aggCols = child.output.map &#123; attr =&gt;</span><br><span class="line">        <span class="keyword">if</span> (keyExprIds.contains(attr.exprId)) &#123;</span><br><span class="line">          attr</span><br><span class="line">        &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">          <span class="type">Alias</span>(<span class="keyword">new</span> <span class="type">First</span>(attr).toAggregateExpression(), attr.name)(attr.exprId)</span><br><span class="line">        &#125;</span><br><span class="line">      &#125;</span><br><span class="line">      <span class="comment">// SPARK-22951: Physical aggregate operators distinguishes global aggregation and grouping</span></span><br><span class="line">      <span class="comment">// aggregations by checking the number of grouping keys. The key difference here is that a</span></span><br><span class="line">      <span class="comment">// global aggregation always returns at least one row even if there are no input rows. Here</span></span><br><span class="line">      <span class="comment">// we append a literal when the grouping key list is empty so that the result aggregate</span></span><br><span class="line">      <span class="comment">// operator is properly treated as a grouping aggregation.</span></span><br><span class="line">      <span class="keyword">val</span> nonemptyKeys = <span class="keyword">if</span> (keys.isEmpty) <span class="type">Literal</span>(<span class="number">1</span>) :: <span class="type">Nil</span> <span class="keyword">else</span> keys</span><br><span class="line">      <span class="type">Aggregate</span>(nonemptyKeys, aggCols, child)</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>可以看到，这段优化做的主要工作是：</p>
<p><strong>将 DeDuplicate 接口优化成聚合算子。</strong></p>
<p>在这个过程中，有几个考虑：</p>
<ul>
<li><p>将所有字段分为两类：<code>keys</code> 和 <code>aggColumns</code>:</p>
<ul>
<li>其中，<code>keys</code> 为被分组的字段，<code>aggColumn</code> 为其他字段；</li>
<li>根据 <code>keys</code> 分组后，取所有 <code>aggColumn</code> 字段在分组中的第一个出现的值作为字段的值。</li>
</ul>
</li>
<li><p>根据 <code>SPARK-22951</code>，解决了当 <code>keys</code> 为空的时候的 Bug.</p>
</li>
</ul>
<h2 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h2><p>根据上面的分析可以知道：</p>
<p>在 Spark DataSet API 中:</p>
<ul>
<li><code>distinct()</code> == <code>dropDuplicates()</code></li>
<li><code>dopDuplicates()</code> 的实现和下述操作没差别：  <figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">df.select($<span class="string">"field_1"</span>, $<span class="string">"field_2"</span>, $<span class="string">"field_3"</span>).dropDuplicates()</span><br><span class="line"></span><br><span class="line"><span class="comment">// almost equilivate:</span></span><br><span class="line"></span><br><span class="line">df.groupBy($<span class="string">"field_1"</span>, $<span class="string">"field_2"</span>, $<span class="string">"field_3"</span>).agg(frist($<span class="string">"field_4"</span>))).drop($<span class="string">"field_4"</span>)</span><br></pre></td></tr></table></figure>
</li>
</ul>
<h1 id="方案二：使用-groupBy"><a href="#方案二：使用-groupBy" class="headerlink" title="方案二：使用 groupBy()"></a>方案二：使用 <code>groupBy()</code></h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">values = df.groupBy(<span class="string">"field_1"</span>, <span class="string">"field_2"</span>, <span class="string">"field_3"</span>).count().drop(<span class="string">"count"</span>).collect()</span><br></pre></td></tr></table></figure>
<h2 id="分析二"><a href="#分析二" class="headerlink" title="分析二"></a>分析二</h2><p>使用 <code>groupBy</code> 接口会创建一个 <code>RelationalGroupedDataset</code>。</p>
<p>在这个 <code>RelationalGroupedDataset</code> 上可以调用一系列的操作符，在上面的方案中，使用了 <code>count</code>。</p>
<p>我们来看一下 <code>count</code> 方法的实现：</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * Count the number of rows for each group.</span></span><br><span class="line"><span class="comment"> * The resulting `DataFrame` will also contain the grouping columns.</span></span><br><span class="line"><span class="comment"> *</span></span><br><span class="line"><span class="comment"> * @since 1.3.0</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">count</span></span>(): <span class="type">DataFrame</span> = toDF(<span class="type">Seq</span>(<span class="type">Alias</span>(<span class="type">Count</span>(<span class="type">Literal</span>(<span class="number">1</span>)).toAggregateExpression(), <span class="string">"count"</span>)()))</span><br></pre></td></tr></table></figure>
<p>其中，<code>Count</code> 操作符的定义如下：</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@ExpressionDescription</span>(</span><br><span class="line">  usage = <span class="string">""</span><span class="string">"</span></span><br><span class="line"><span class="string">    _FUNC_(*) - Returns the total number of retrieved rows, including rows containing null.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    _FUNC_(expr[, expr...]) - Returns the number of rows for which the supplied expression(s) are all non-null.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    _FUNC_(DISTINCT expr[, expr...]) - Returns the number of rows for which the supplied expression(s) are unique and non-null.</span></span><br><span class="line"><span class="string">  "</span><span class="string">""</span>)</span><br><span class="line"><span class="comment">// scalastyle:on line.size.limit</span></span><br><span class="line"><span class="keyword">case</span> <span class="class"><span class="keyword">class</span> <span class="title">Count</span>(<span class="params">children: <span class="type">Seq</span>[<span class="type">Expression</span>]</span>) <span class="keyword">extends</span> <span class="title">CountLike</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">override</span> <span class="keyword">lazy</span> <span class="keyword">val</span> updateExpressions = &#123;</span><br><span class="line">    <span class="keyword">val</span> nullableChildren = children.filter(_.nullable)</span><br><span class="line">    <span class="keyword">if</span> (nullableChildren.isEmpty) &#123;</span><br><span class="line">      <span class="type">Seq</span>(</span><br><span class="line">        <span class="comment">/* count = */</span> count + <span class="number">1</span>L</span><br><span class="line">      )</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">      <span class="type">Seq</span>(</span><br><span class="line">        <span class="comment">/* count = */</span> <span class="type">If</span>(nullableChildren.map(<span class="type">IsNull</span>).reduce(<span class="type">Or</span>), count, count + <span class="number">1</span>L)</span><br><span class="line">      )</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">Count</span> </span>&#123;</span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">apply</span></span>(child: <span class="type">Expression</span>): <span class="type">Count</span> = <span class="type">Count</span>(child :: <span class="type">Nil</span>)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h2 id="小结-1"><a href="#小结-1" class="headerlink" title="小结"></a>小结</h2><p>由上面的分析可以知道，如果使用 <code>.count()</code> 算子，至少需要遍历 rdd 的每个分区。</p>
<h1 id="初步结论"><a href="#初步结论" class="headerlink" title="初步结论"></a>初步结论</h1><p>直接使用 <code>distinct()</code> 方法和使用 <code>groupBy</code> + <code>count</code> 的方法原理类似，但似乎后者性能更差，因为需要遍历每个分区计算总和。</p>
<h1 id="真的吗？"><a href="#真的吗？" class="headerlink" title="真的吗？"></a>真的吗？</h1><p>如果单独使用 <code>count()</code> 性能确实不如直接使用 <code>distinct()</code> 方法。</p>
<p>但是，在 <code>count()</code> 后加上 <code>drop(&quot;count&quot;)</code> 后，情况就不一样了。</p>
<p>我们来看一下执行计划:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line">df.groupBy(&quot;State&quot;, &quot;City&quot;, &quot;Department&quot;, &quot;Quarter Ending&quot;).count().drop(&quot;count&quot;).explain(True)</span><br><span class="line"></span><br><span class="line">== Parsed Logical Plan ==</span><br><span class="line">Project [State#16, City#15, Department#11, Quarter Ending#10]</span><br><span class="line">+- Aggregate [State#16, City#15, Department#11, Quarter Ending#10], [State#16, City#15, Department#11, Quarter Ending#10, count(1) AS count#559L]</span><br><span class="line">   +- Relation[Quarter Ending#10,Department#11,UnitNo#12,Vendor Number#13,Vendor#14,City#15,State#16,DeptID Description#17,DeptID#18,Amount#19,Account#20,AcctNo#21,Fund Description#22,Fund#23] csv</span><br><span class="line"></span><br><span class="line">== Analyzed Logical Plan ==</span><br><span class="line">State: string, City: string, Department: string, Quarter Ending: string</span><br><span class="line">Project [State#16, City#15, Department#11, Quarter Ending#10]</span><br><span class="line">+- Aggregate [State#16, City#15, Department#11, Quarter Ending#10], [State#16, City#15, Department#11, Quarter Ending#10, count(1) AS count#559L]</span><br><span class="line">   +- Relation[Quarter Ending#10,Department#11,UnitNo#12,Vendor Number#13,Vendor#14,City#15,State#16,DeptID Description#17,DeptID#18,Amount#19,Account#20,AcctNo#21,Fund Description#22,Fund#23] csv</span><br><span class="line"></span><br><span class="line">== Optimized Logical Plan ==</span><br><span class="line">Aggregate [State#16, City#15, Department#11, Quarter Ending#10], [State#16, City#15, Department#11, Quarter Ending#10]</span><br><span class="line">+- Project [Quarter Ending#10, Department#11, City#15, State#16]</span><br><span class="line">   +- Relation[Quarter Ending#10,Department#11,UnitNo#12,Vendor Number#13,Vendor#14,City#15,State#16,DeptID Description#17,DeptID#18,Amount#19,Account#20,AcctNo#21,Fund Description#22,Fund#23] csv</span><br><span class="line"></span><br><span class="line">== Physical Plan ==</span><br><span class="line">*(2) HashAggregate(keys=[State#16, City#15, Department#11, Quarter Ending#10], functions=[], output=[State#16, City#15, Department#11, Quarter Ending#10])</span><br><span class="line">+- Exchange hashpartitioning(State#16, City#15, Department#11, Quarter Ending#10, 200)</span><br><span class="line">   +- *(1) HashAggregate(keys=[State#16, City#15, Department#11, Quarter Ending#10], functions=[], output=[State#16, City#15, Department#11, Quarter Ending#10])</span><br><span class="line">      +- *(1) FileScan csv [Quarter Ending#10,Department#11,City#15,State#16] Batched: false, Format: CSV, Location: InMemoryFileIndex[file:/home/jovyan/work/Vermont_Vendor_Payments.csv], PartitionFilters: [], PushedFilters: [], ReadSchema: struct&lt;Quarter Ending:string,Department:string,City:string,State:string&gt;</span><br></pre></td></tr></table></figure>
<p>可以看到，<strong>优化器</strong>在将逻辑执行计划优化的过程中，将 <code>Aggregate function</code> 去掉了，从最终的<strong>物理执行计划</strong>中也能看出，最终已经没有了 <code>Aggregate function</code>。</p>
<p>最后我们来看一下直接使用 <code>distinct()</code> 的物理执行计划：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">df.select(&quot;State&quot;, &quot;City&quot;, &quot;Department&quot;, &quot;Quarter Ending&quot;).distinct().explain()</span><br><span class="line"></span><br><span class="line">== Physical Plan ==</span><br><span class="line">*(2) HashAggregate(keys=[State#16, City#15, Department#11, Quarter Ending#10], functions=[])</span><br><span class="line">+- Exchange hashpartitioning(State#16, City#15, Department#11, Quarter Ending#10, 200)</span><br><span class="line">   +- *(1) HashAggregate(keys=[State#16, City#15, Department#11, Quarter Ending#10], functions=[])</span><br><span class="line">      +- *(1) Project [State#16, City#15, Department#11, Quarter Ending#10]</span><br><span class="line">         +- *(1) FileScan csv [Quarter Ending#10,Department#11,City#15,State#16] Batched: false, Format: CSV, Location: InMemoryFileIndex[file:/home/jovyan/work/Vermont_Vendor_Payments.csv], PartitionFilters: [], PushedFilters: [], ReadSchema: struct&lt;Quarter Ending:string,Department:string,City:string,State:string&gt;</span><br></pre></td></tr></table></figure>
<p>可以看到，两者的物理执行计划几乎是一模一样的，唯一的差别在于后者多了一步 <code>select</code> 的操作。</p>
<h1 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h1><p>根据上面的分析，我们可以知道，上述两种方案的性能应该是几乎一样的，都可以使用，任君选择。</p>

      
    </div>

    
      
      



      
      
    

    
      <footer class="post-footer">
        
          <div class="post-tags">
            
              <a href="/tags/数据处理/">数据处理</a>
            
              <a href="/tags/Spark/">Spark</a>
            
              <a href="/tags/源码分析/">源码分析</a>
            
          </div>
        
        
        
  <nav class="post-nav">
    
    
      <a class="next" href="/2019/04/08/scala-nothingness/">
        <span class="next-text nav-default">Scala Nothingness</span>
        <span class="prev-text nav-mobile">下一篇</span>
        <i class="iconfont icon-right"></i>
      </a>
    
  </nav>


      </footer>
    

  </article>


          </div>
          
  <div class="comments" id="comments">
    
      <div id="vcomments"></div>
    
  </div>


        </div>
      </main>

      <footer id="footer" class="footer">

  <div class="social-links">
    
      
        
          <a href="mailto:pengye91@gmail.com" class="iconfont icon-email" title="email"></a>
        
      
    
      
    
      
    
      
    
      
    
      
    
      
        
          <a href="https://github.com/pengye91" class="iconfont icon-github" title="github"></a>
        
      
    
      
    
      
    
      
    
      
    
      
    
      
    

    
      
      <a href="/atom.xml" class="iconfont icon-rss" title="rss"></a>
    
  </div>



<div class="copyright">
  <span class="power-by">
    由 <a class="hexo-link" href="https://hexo.io/">Hexo</a> 强力驱动
  </span>
  <span class="division">|</span>
  <span class="theme-info">
    主题 - 
    <a class="theme-link" href="https://github.com/ahonn/hexo-theme-even">Even</a>
  </span>

  <span class="copyright-year">
    
    &copy; 
     
      2018 - 
    
    2019

    <span class="heart">
      <i class="iconfont icon-heart"></i>
    </span>
    <span class="author">xyp</span>
  </span>
</div>

      </footer>

      <div class="back-to-top" id="back-to-top">
        <i class="iconfont icon-up"></i>
      </div>
    </div>

    
  
  
<!-- valine Comments -->
<script src="//cdn1.lncld.net/static/js/3.0.4/av-min.js"></script>
<script src="//cdn.jsdelivr.net/gh/xcss/valine@v1.3.3/dist/Valine.min.js"></script>
<script type="text/javascript">
    new Valine({
        el: '#vcomments',
        notify: false,
        verify: false,
        visitor: true,
        app_id: "xeDhasO1xV7F1SpCG0oRuiol-gzGzoHsz",
        app_key: "wgFvo2YMOmn0Qcv7YPFxtePy",
        placeholder: "在此评论......",
        avatar: 'identicon'
    });
</script>


  

  



    
  



  
  





  
    <script type="text/javascript" src="/lib/jquery/jquery.min.js"></script>
  

  
    <script type="text/javascript" src="/lib/slideout/slideout.js"></script>
  

  
    <script type="text/javascript" src="/lib/fancybox/jquery.fancybox.pack.js"></script>
  

  
    <script type="text/javascript" src="/lib/pjax/jquery.pjax.min.js"></script>
  

  
    <script type="text/javascript" src="/lib/nprogress/nprogress.min.js"></script>
  


    <script type="text/javascript" src="/js/src/even.js?v=2.10.1"></script>

  </body>
</html>
