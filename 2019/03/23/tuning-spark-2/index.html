<!DOCTYPE html>
<html lang="zh-CN">
  <head>
    
<meta charset="UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>


<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />

<meta name="theme-color" content="#f8f5ec" />
<meta name="msapplication-navbutton-color" content="#f8f5ec">
<meta name="apple-mobile-web-app-capable" content="yes">
<meta name="apple-mobile-web-app-status-bar-style" content="#f8f5ec">



  <meta name="description" content="Spark 调优 下"/>




  <meta name="keywords" content="数据处理, Spark, 调优, Lingering Fragments" />










  <link rel="alternate" href="/default" title="Lingering Fragments">




  <link rel="shortcut icon" type="image/x-icon" href="/favicon.ico?v=2.10.1" />



<link rel="canonical" href="https://pengye91.github.io/2019/03/23/tuning-spark-2/"/>



  <link rel="stylesheet" type="text/css" href="/lib/fancybox/jquery.fancybox.css" />




  <link rel="stylesheet" type="text/css" href="/lib/nprogress/nprogress.min.css" />



<link rel="stylesheet" type="text/css" href="/css/style.css?v=2.10.1" />



  


<!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-127442719-1"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'UA-127442719-1');
</script>


  <script id="baidu_push">
(function(){
    var bp = document.createElement('script');
    var curProtocol = window.location.protocol.split(':')[0];
    if (curProtocol === 'https') {
        bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';
    }
    else {
        bp.src = 'http://push.zhanzhang.baidu.com/push.js';
    }
    var s = document.getElementsByTagName("script")[0];
    s.parentNode.insertBefore(bp, s);
})();
</script>








<script>
  window.config = {"title":"Lingering Fragments","subtitle":"一些想法和总结","description":null,"author":"xyp","language":"zh-CN","timezone":"Asia/Shanghai","url":"https://pengye91.github.io","root":"/","permalink":":year/:month/:day/:title/","permalink_defaults":null,"source_dir":"source","public_dir":"public","tag_dir":"tags","archive_dir":"archives","category_dir":"categories","code_dir":"downloads/code","i18n_dir":":lang","skip_render":null,"new_post_name":":title.md","default_layout":"post","titlecase":false,"external_link":true,"filename_case":0,"render_drafts":false,"post_asset_folder":false,"relative_link":false,"future":true,"highlight":{"enable":true,"auto_detect":false,"line_number":true,"tab_replace":null,"first_line_number":"always1"},"default_category":"uncategorized","category_map":null,"tag_map":null,"date_format":"YYYY-MM-DD","time_format":"HH:mm:ss","per_page":10,"pagination_dir":"page","theme":"even","deploy":{"type":"git","repo":"https://github.com/pengye91/pengye91.github.io.git","branch":"master"},"ignore":[],"keywords":null,"index_generator":{"per_page":10,"order_by":"-date","path":""},"sitemap":{"path":"sitemap.xml"},"baidusitemap":{"path":"baidusitemap.xml"},"archive_generator":{"per_page":10,"yearly":true,"monthly":true,"daily":false},"category_generator":{"per_page":10},"tag_generator":{"per_page":10},"marked":{"gfm":true,"pedantic":false,"sanitize":false,"tables":true,"breaks":true,"smartLists":true,"smartypants":true,"modifyAnchors":"","autolink":true},"server":{"port":4000,"log":false,"compress":false,"header":true},"since":2018,"favicon":"/favicon.ico","rss":"default","menu":{"Home":"/","Archives":"/archives/","Tags":"/tags","Categories":"/categories","About":"/about"},"color":"cobalt blue","mode":"default","toc":true,"fancybox":true,"pjax":true,"copyright":{"enable":false,"license":"<a rel=\"license\" href=\"http://creativecommons.org/licenses/by-nc/4.0/\" target=\"_blank\">知识共享署名-非商业性使用 4.0 国际许可协议</a>"},"reward":{"enable":false,"qrCode":{"wechat":null,"alipay":null}},"social":{"email":"pengye91@gmail.com","stack-overflow":null,"twitter":null,"facebook":null,"linkedin":null,"google":null,"github":"https://github.com/pengye91","weibo":null,"zhihu":null,"douban":null,"pocket":null,"tumblr":null,"instagram":null},"leancloud":{"app_id":null,"app_key":null},"baidu_analytics":null,"baidu_verification":null,"google_analytics":"UA-127442719-1","google_verification":null,"disqus_shortname":null,"valine":{"appid":"xeDhasO1xV7F1SpCG0oRuiol-gzGzoHsz","appkey":"wgFvo2YMOmn0Qcv7YPFxtePy","notify":false,"verify":false,"avatar":"identicon","visitor":true,"placeholder":"在此评论......"},"changyan":{"appid":null,"appkey":null},"livere_datauid":null,"version":"2.10.1"};
</script>

    <title> Spark 调优 下 - Lingering Fragments </title>
  </head>

  <body><div id="mobile-navbar" class="mobile-navbar">
  <div class="mobile-header-logo">
    <a href="/." class="logo">Lingering Fragments</a>
  </div>
  <div class="mobile-navbar-icon">
    <span></span>
    <span></span>
    <span></span>
  </div>
</div>

<nav id="mobile-menu" class="mobile-menu slideout-menu">
  <ul class="mobile-menu-list">
    
      <a href="/">
        <li class="mobile-menu-item">
          
          
            首页
          
        </li>
      </a>
    
      <a href="/archives/">
        <li class="mobile-menu-item">
          
          
            归档
          
        </li>
      </a>
    
      <a href="/tags">
        <li class="mobile-menu-item">
          
          
            标签
          
        </li>
      </a>
    
      <a href="/categories">
        <li class="mobile-menu-item">
          
          
            分类
          
        </li>
      </a>
    
      <a href="/about">
        <li class="mobile-menu-item">
          
          
            关于
          
        </li>
      </a>
    
  </ul>
</nav>

    <div class="container" id="mobile-panel">
      <header id="header" class="header"><div class="logo-wrapper">
  <a href="/." class="logo">Lingering Fragments</a>
</div>

<nav class="site-navbar">
  
    <ul id="menu" class="menu">
      
        <li class="menu-item">
          <a class="menu-item-link" href="/">
            
            
              首页
            
          </a>
        </li>
      
        <li class="menu-item">
          <a class="menu-item-link" href="/archives/">
            
            
              归档
            
          </a>
        </li>
      
        <li class="menu-item">
          <a class="menu-item-link" href="/tags">
            
            
              标签
            
          </a>
        </li>
      
        <li class="menu-item">
          <a class="menu-item-link" href="/categories">
            
            
              分类
            
          </a>
        </li>
      
        <li class="menu-item">
          <a class="menu-item-link" href="/about">
            
            
              关于
            
          </a>
        </li>
      
    </ul>
  
</nav>

      </header>

      <main id="main" class="main">
        <div class="content-wrapper">
          <div id="content" class="content">
            
  
  <article class="post">
    <header class="post-header">
      <h1 class="post-title">
        
          Spark 调优 下
        
      </h1>

      <div class="post-meta">
        <span class="post-time">
          2019-03-23
        </span>
        
          <span class="post-category">
            
              <a href="/categories/Spark/">Spark</a>
            
              <a href="/categories/Spark/调优/">调优</a>
            
              <a href="/categories/Spark/调优/数据处理/">数据处理</a>
            
          </span>
        
        
      </div>
    </header>

    
    
  <div class="post-toc" id="post-toc">
    <h2 class="post-toc-title">文章目录</h2>
    <div class="post-toc-content">
      <ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#资源分配调优"><span class="toc-text">资源分配调优</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#CPU-和-内存"><span class="toc-text">CPU 和 内存</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Executor"><span class="toc-text">Executor</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Yarn-资源"><span class="toc-text">Yarn 资源</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#并发度调优"><span class="toc-text">并发度调优</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#需要考虑的点"><span class="toc-text">需要考虑的点</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#防止臃肿的数据结构"><span class="toc-text">防止臃肿的数据结构</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#数据格式"><span class="toc-text">数据格式</span></a></li></ol>
    </div>
  </div>



    <div class="post-content">
      
        <blockquote>
<p>本篇文章是在结合自己业务和<a href="https://blog.cloudera.com/blog/2015/03/how-to-tune-your-apache-spark-jobs-part-2/" target="_blank" rel="noopener">这篇文章</a>的基础上写的。</p>
</blockquote>
<p>话接上文， 了解了 Spark 运行时机制后，需要通过下面几种方法来最大化利用集群资源：</p>
<ul>
<li>正确的资源配置；</li>
<li>正确的并行度配置；</li>
<li>数据本身属性配置。</li>
</ul>
<a id="more"></a>
<h2 id="资源分配调优"><a href="#资源分配调优" class="headerlink" title="资源分配调优"></a>资源分配调优</h2><p>本文主要描述 <code>spark-on-yarn</code>。</p>
<p>在运行过程中，Spark 主要考虑两个资源：<em>CPU 和 内存</em>。</p>
<h3 id="CPU-和-内存"><a href="#CPU-和-内存" class="headerlink" title="CPU 和 内存"></a>CPU 和 内存</h3><p>每个 Executor 都有固定数量的 CPU 核 <code>--executor-cores</code> 和 固定的内存堆大小 <code>--executor-memory</code>.</p>
<ul>
<li><code>cores</code> 参数决定了每个 executor 能并行执行的最大任务数。</li>
<li><code>memory</code> 参数会影响两个功能：<ul>
<li>Spark 能 cache 的数据量；</li>
<li>在 <code>grouping</code>, <code>aggregations</code> 和 <code>join</code> 阶段能 shuffle 的数据量；</li>
</ul>
</li>
</ul>
<h3 id="Executor"><a href="#Executor" class="headerlink" title="Executor"></a>Executor</h3><p><code>--num-executors</code> 控制了 Executor 的数量。</p>
<p>从 Spark 1.3 开始，可以通过设置 <code>spark.dynamicAllocation.enabled</code> 属性为 <code>true</code> 来动态申请 Executor:</p>
<ul>
<li>当有一定数量的处于 pending 状态的 task ，并且集群中有可用的资源时，会分配新的 Executor 给应用。</li>
</ul>
<h3 id="Yarn-资源"><a href="#Yarn-资源" class="headerlink" title="Yarn 资源"></a>Yarn 资源</h3><p>Spark 的资源分配还受到 Yarn 配置的影响：</p>
<p>对于 <code>cores</code> 配置，Yarn 会分配相应个数的 <code>vcores</code> 。</p>
<p>对于 内存 配置而言，会复杂一点：</p>
<center><img src="/images/spark_tuning/1553234340910.png" alt="Alt text"></center>

<p>除了上述考虑外，还有几点值得注意的：</p>
<ul>
<li>driver 的内存和 CPU 可以通过 <code>--driver-memory</code> 和 <code>--driver-cores</code> 参数来调节。</li>
<li>executor 的内存如果过大可能会导致 GC 时间超长。单个 executor 的内存最好<strong>不要超过 64 G</strong>，即 <code>--executor-memory &lt; 64G</code> 。</li>
<li>HDFS 对于大量并发的处理有困难，一般建议每个 executor 的<strong>核数不要超过 5 个</strong>，即 <code>--executor-cores &lt;= 5</code>；</li>
<li>如果 executor 的配置太小了（比如只有 1 个核和 1 G 的内存）会丢失单个 JVM 内运行多个任务的优势：比如，<strong>广播变量</strong> 会被复制传送给每个 executor，如果一个 executor 不能并发执行任务，会导致复制太多 <strong>广播变量</strong>，或者等待的任务数过多。</li>
</ul>
<h2 id="并发度调优"><a href="#并发度调优" class="headerlink" title="并发度调优"></a>并发度调优</h2><p>Spark 本质上是一个<strong>并行数据处理引擎</strong>。和所有并行处理器一样，<em>并发度</em>对于系统的性能至关重要。</p>
<p>每个 Spark Stage 都有多个 task，每个 task 会依次处理数据。</p>
<p>在 Spark 调优的过程中，任务数可能是最重要的一个调优参数了。</p>
<p><strong>每个阶段(Stage)中的任务数量 == 上一个 RDD 的分区数。</strong></p>
<p><strong>一个 RDD 的分区数量 == 它依赖的上一个 RDD 的分区数量。</strong>这个结论有以下几个例外：</p>
<ul>
<li><code>coalesce(numPartitions)</code> 会创建一个比父 RDD 分区更少的 RDD；</li>
<li><code>union</code> 会创建一个父 RDD 分区之和的分区数量；</li>
<li><code>cartesian</code> 会创建一个 笛卡尔乘积 个数分区的 RDD。</li>
</ul>
<p><strong>对于没有父 RDD 的 RDD(比如由 <code>textFile</code> 产生的 RDD)，分区数量由底层 MapReduce InputFormat 决定。</strong>通常来说，一个 HDFS Block 会对应一个 分区。如果没有特殊参数，Spark 使用 <code>spark.default.parallelism</code> 来决定分区数量。</p>
<p><strong>调用 rdd.partitions.size 可以查看一个 rdd 的分区数量。</strong> </p>
<h3 id="需要考虑的点"><a href="#需要考虑的点" class="headerlink" title="需要考虑的点"></a>需要考虑的点</h3><p><strong>task 数量太小</strong></p>
<ul>
<li>如果 task 的数量小于 所有 slots 数量，会造成 CPU 浪费；</li>
<li><p>除此之外，task 太少还会给每个 task 中的 聚合操作 带来很大的内存压力：</p>
<ul>
<li><code>join</code>, <code>cogroup</code> 和 <code>*ByKey</code> 操作都涉及到将数据存在 哈希表 或者内存中用于分组和排序：<ul>
<li><code>join</code>, <code>cogroup</code> 和 <code>groupByKey</code> 都在一个 shuffle 的取数据一端将使用数据；</li>
<li><code>reduceByKey</code> 和 <code>aggregateByKey</code> 会在 shuffle 的两端都使用这些数据。</li>
</ul>
</li>
</ul>
</li>
<li><p>当这些聚合操作的数据量比可用内存大很多时，就有很多混乱的现象可能发生：</p>
<ol>
<li>在 HashMap 或者 Mem Buffer 中保存这么多数据量会给 GC 带来很大压力。甚至可能直接停止这个 JVM 进程。</li>
<li>当数据量太大时，Spark 可能会将数据保存在磁盘上，这样的操作在大的 shuffle 阶段会造成严重的性能瓶颈；</li>
</ol>
</li>
<li><p><strong>解决</strong></p>
<ul>
<li>当这个 Stage 是直接从 Hadoop 读取数据时，可以：<ul>
<li>调用 <code>repartition</code> 操作(会造成 shuffle)；</li>
<li>配置 <code>InputFormat</code> 以创建更多 splits;</li>
<li><strong>在写入数据到 HDFS 的时候使用一个更小的 blockSize</strong>。</li>
</ul>
</li>
<li><p>如果这个 Stage 是从上一个 Stage 拿到数据的，可以：</p>
<ul>
<li>在上一个 Stage 触发 shuffle 时的 transformation 可以接收一个 <code>numPartitions</code> 参数：  <figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">val</span> rdd2 = rdd2.reduceByKey(_ + _, numPartitions = <span class="type">X</span>)</span><br></pre></td></tr></table></figure>
</li>
</ul>
</li>
<li><p><code>X</code> 应该是多少？</p>
<ol>
<li>最方便的解决办法：<strong>试</strong><br> 假设父 RDD 的分区数量(通过 <code>rdd.partitions.size</code> 查看)是 <code>Y</code>：<pre><code>`让 X = Y * 1.5`，不停重试，直到性能不再增加。
</code></pre></li>
<li>另外还有一个通用方法，但在日常工作应用并不实际: <strong>主要目标是运行足够的任务，以便每个任务不会 OOM</strong><ul>
<li>每个任务可用的内存大小为：<br>  <code>spark.executor.memory * spark.shuffle.memoryFraction * spark.shuffle.safetyFraction/ spark.executor.cores</code></li>
</ul>
</li>
</ol>
</li>
</ul>
</li>
</ul>
<p>总的来说，在 Spark 应用中，<strong>提高任务的数量总是更好的选择</strong>，如果出现问题可以再调整。</p>
<p>这和 <code>MapReduce</code> 任务的调优不同，在 <code>MapReduce</code> 中，要求任务数的设置更保守一些。</p>
<p>这是因为两者在 <code>MapReduce</code> 中任务的启动开销更大得多。</p>
<h2 id="防止臃肿的数据结构"><a href="#防止臃肿的数据结构" class="headerlink" title="防止臃肿的数据结构"></a>防止臃肿的数据结构</h2><p>在 Spark 中数据以 <code>Records</code> 的形式流转。每条数据记录都有两种呈现的形式：</p>
<ul>
<li>一个反序列化的 <code>Java 对象</code></li>
<li>一个 <code>序列化二进制对象</code></li>
</ul>
<p>通常来说，Spark 在内存中使用 <code>反序列化对象</code>，在硬盘和网络传输中使用 <code>序列化对象</code>。</p>
<p><code>spark.serializer</code> 用于在两种呈现方式之间转换，通常推荐使用 <code>org.apache.spark.serializer.KryoSerializer</code>。</p>
<p>如果反序列化对象太过臃肿，会导致：</p>
<ul>
<li>Spark 将数据 dump 到硬盘的次数增加；</li>
<li>可以 <code>cache</code> 的数据数量减少；</li>
</ul>
<p><a href="http://spark.apache.org/docs/2.2.1/tuning.html#memory-tuning" target="_blank" rel="noopener">官方文档</a>有专门的章节描述该如何调优：</p>
<blockquote>
<p>在考虑内存使用调优时，有三个考虑因素：</p>
<ol>
<li>你所有对象的内存使用总量</li>
<li>获取对象的代价</li>
<li>GC 的开销</li>
</ol>
</blockquote>
<h2 id="数据格式"><a href="#数据格式" class="headerlink" title="数据格式"></a>数据格式</h2><p>如果可能，尽量使用 可扩展的二进制格式: <code>Avro</code>, <code>Parquet</code>, <code>Thrift</code>, <code>Protobuf</code> 作为存储文件的格式。</p>
<p>一个奇怪但是合理的建议：存储时，使用 <code>Hadoop SequenceFile</code>，只是每条数据的格式是上述之一。</p>
<p>不选择直接使用上述格式的文件的原因是：单个文件的 Size 太小了，如果直接存储对 Namenode 的压力过大。</p>
<p>（完）</p>

      
    </div>

    
      
      



      
      
    

    
      <footer class="post-footer">
        
          <div class="post-tags">
            
              <a href="/tags/数据处理/">数据处理</a>
            
              <a href="/tags/Spark/">Spark</a>
            
              <a href="/tags/调优/">调优</a>
            
          </div>
        
        
        
  <nav class="post-nav">
    
      <a class="prev" href="/2019/04/07/spark-to-hive/">
        <i class="iconfont icon-left"></i>
        <span class="prev-text nav-default">Spark 输出到 Hive 总结</span>
        <span class="prev-text nav-mobile">上一篇</span>
      </a>
    
    
      <a class="next" href="/2019/03/22/tuning-spark-1/">
        <span class="next-text nav-default">Spark 调优 上</span>
        <span class="prev-text nav-mobile">下一篇</span>
        <i class="iconfont icon-right"></i>
      </a>
    
  </nav>


      </footer>
    

  </article>


          </div>
          
  <div class="comments" id="comments">
    
      <div id="vcomments"></div>
    
  </div>


        </div>
      </main>

      <footer id="footer" class="footer">

  <div class="social-links">
    
      
        
          <a href="mailto:pengye91@gmail.com" class="iconfont icon-email" title="email"></a>
        
      
    
      
    
      
    
      
    
      
    
      
    
      
        
          <a href="https://github.com/pengye91" class="iconfont icon-github" title="github"></a>
        
      
    
      
    
      
    
      
    
      
    
      
    
      
    

    
      
      <a href="/atom.xml" class="iconfont icon-rss" title="rss"></a>
    
  </div>



<div class="copyright">
  <span class="power-by">
    由 <a class="hexo-link" href="https://hexo.io/">Hexo</a> 强力驱动
  </span>
  <span class="division">|</span>
  <span class="theme-info">
    主题 - 
    <a class="theme-link" href="https://github.com/ahonn/hexo-theme-even">Even</a>
  </span>

  <span class="copyright-year">
    
    &copy; 
     
      2018 - 
    
    2020

    <span class="heart">
      <i class="iconfont icon-heart"></i>
    </span>
    <span class="author">xyp</span>
  </span>
</div>

      </footer>

      <div class="back-to-top" id="back-to-top">
        <i class="iconfont icon-up"></i>
      </div>
    </div>

    
  
  
<!-- valine Comments -->
<script src='//unpkg.com/valine/dist/Valine.min.js'></script>

<script type="text/javascript">
    new Valine({
        el: '#vcomments',
        visitor: true,
        app_id: "xeDhasO1xV7F1SpCG0oRuiol-gzGzoHsz",
        app_key: "wgFvo2YMOmn0Qcv7YPFxtePy",
        placeholder: "在此评论......",
        avatar: 'identicon'
    });
</script>


  

  



    
  



  
  





  
    <script type="text/javascript" src="/lib/jquery/jquery.min.js"></script>
  

  
    <script type="text/javascript" src="/lib/slideout/slideout.js"></script>
  

  
    <script type="text/javascript" src="/lib/fancybox/jquery.fancybox.pack.js"></script>
  

  
    <script type="text/javascript" src="/lib/pjax/jquery.pjax.min.js"></script>
  

  
    <script type="text/javascript" src="/lib/nprogress/nprogress.min.js"></script>
  


    <script type="text/javascript" src="/js/src/even.js?v=2.10.1"></script>

  </body>
</html>
