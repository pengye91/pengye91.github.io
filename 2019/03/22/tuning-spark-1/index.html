<!DOCTYPE html>
<html lang="zh-CN">
  <head>
    
<meta charset="UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>


<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />

<meta name="theme-color" content="#f8f5ec" />
<meta name="msapplication-navbutton-color" content="#f8f5ec">
<meta name="apple-mobile-web-app-capable" content="yes">
<meta name="apple-mobile-web-app-status-bar-style" content="#f8f5ec">



  <meta name="description" content="Spark 调优 上"/>




  <meta name="keywords" content="数据处理, Spark, 调优, Lingering Fragments" />










  <link rel="alternate" href="/default" title="Lingering Fragments">




  <link rel="shortcut icon" type="image/x-icon" href="/favicon.ico?v=2.10.1" />



<link rel="canonical" href="https://pengye91.github.io/2019/03/22/tuning-spark-1/"/>



  <link rel="stylesheet" type="text/css" href="/lib/fancybox/jquery.fancybox.css" />




  <link rel="stylesheet" type="text/css" href="/lib/nprogress/nprogress.min.css" />



<link rel="stylesheet" type="text/css" href="/css/style.css?v=2.10.1" />



  


<!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-127442719-1"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'UA-127442719-1');
</script>


  <script id="baidu_push">
(function(){
    var bp = document.createElement('script');
    var curProtocol = window.location.protocol.split(':')[0];
    if (curProtocol === 'https') {
        bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';
    }
    else {
        bp.src = 'http://push.zhanzhang.baidu.com/push.js';
    }
    var s = document.getElementsByTagName("script")[0];
    s.parentNode.insertBefore(bp, s);
})();
</script>








<script>
  window.config = {"title":"Lingering Fragments","subtitle":"一些想法和总结","description":null,"author":"xyp","language":"zh-CN","timezone":"Asia/Shanghai","url":"https://pengye91.github.io","root":"/","permalink":":year/:month/:day/:title/","permalink_defaults":null,"source_dir":"source","public_dir":"public","tag_dir":"tags","archive_dir":"archives","category_dir":"categories","code_dir":"downloads/code","i18n_dir":":lang","skip_render":null,"new_post_name":":title.md","default_layout":"post","titlecase":false,"external_link":true,"filename_case":0,"render_drafts":false,"post_asset_folder":false,"relative_link":false,"future":true,"highlight":{"enable":true,"auto_detect":false,"line_number":true,"tab_replace":null,"first_line_number":"always1"},"default_category":"uncategorized","category_map":null,"tag_map":null,"date_format":"YYYY-MM-DD","time_format":"HH:mm:ss","per_page":10,"pagination_dir":"page","theme":"even","deploy":{"type":"git","repo":"https://github.com/pengye91/pengye91.github.io.git","branch":"master"},"ignore":[],"keywords":null,"index_generator":{"per_page":10,"order_by":"-date","path":""},"sitemap":{"path":"sitemap.xml"},"baidusitemap":{"path":"baidusitemap.xml"},"archive_generator":{"per_page":10,"yearly":true,"monthly":true,"daily":false},"category_generator":{"per_page":10},"tag_generator":{"per_page":10},"marked":{"gfm":true,"pedantic":false,"sanitize":false,"tables":true,"breaks":true,"smartLists":true,"smartypants":true,"modifyAnchors":"","autolink":true},"server":{"port":4000,"log":false,"compress":false,"header":true},"since":2018,"favicon":"/favicon.ico","rss":"default","menu":{"Home":"/","Archives":"/archives/","Tags":"/tags","Categories":"/categories","About":"/about"},"color":"cobalt blue","mode":"default","toc":true,"fancybox":true,"pjax":true,"copyright":{"enable":false,"license":"<a rel=\"license\" href=\"http://creativecommons.org/licenses/by-nc/4.0/\" target=\"_blank\">知识共享署名-非商业性使用 4.0 国际许可协议</a>"},"reward":{"enable":false,"qrCode":{"wechat":null,"alipay":null}},"social":{"email":"pengye91@gmail.com","stack-overflow":null,"twitter":null,"facebook":null,"linkedin":null,"google":null,"github":"https://github.com/pengye91","weibo":null,"zhihu":null,"douban":null,"pocket":null,"tumblr":null,"instagram":null},"leancloud":{"app_id":null,"app_key":null},"baidu_analytics":null,"baidu_verification":null,"google_analytics":"UA-127442719-1","google_verification":null,"disqus_shortname":null,"valine":{"appid":"xeDhasO1xV7F1SpCG0oRuiol-gzGzoHsz","appkey":"wgFvo2YMOmn0Qcv7YPFxtePy","notify":false,"verify":false,"avatar":"identicon","visitor":true,"placeholder":"在此评论......"},"changyan":{"appid":null,"appkey":null},"livere_datauid":null,"version":"2.10.1"};
</script>

    <title> Spark 调优 上 - Lingering Fragments </title>
  </head>

  <body><div id="mobile-navbar" class="mobile-navbar">
  <div class="mobile-header-logo">
    <a href="/." class="logo">Lingering Fragments</a>
  </div>
  <div class="mobile-navbar-icon">
    <span></span>
    <span></span>
    <span></span>
  </div>
</div>

<nav id="mobile-menu" class="mobile-menu slideout-menu">
  <ul class="mobile-menu-list">
    
      <a href="/">
        <li class="mobile-menu-item">
          
          
            首页
          
        </li>
      </a>
    
      <a href="/archives/">
        <li class="mobile-menu-item">
          
          
            归档
          
        </li>
      </a>
    
      <a href="/tags">
        <li class="mobile-menu-item">
          
          
            标签
          
        </li>
      </a>
    
      <a href="/categories">
        <li class="mobile-menu-item">
          
          
            分类
          
        </li>
      </a>
    
      <a href="/about">
        <li class="mobile-menu-item">
          
          
            关于
          
        </li>
      </a>
    
  </ul>
</nav>

    <div class="container" id="mobile-panel">
      <header id="header" class="header"><div class="logo-wrapper">
  <a href="/." class="logo">Lingering Fragments</a>
</div>

<nav class="site-navbar">
  
    <ul id="menu" class="menu">
      
        <li class="menu-item">
          <a class="menu-item-link" href="/">
            
            
              首页
            
          </a>
        </li>
      
        <li class="menu-item">
          <a class="menu-item-link" href="/archives/">
            
            
              归档
            
          </a>
        </li>
      
        <li class="menu-item">
          <a class="menu-item-link" href="/tags">
            
            
              标签
            
          </a>
        </li>
      
        <li class="menu-item">
          <a class="menu-item-link" href="/categories">
            
            
              分类
            
          </a>
        </li>
      
        <li class="menu-item">
          <a class="menu-item-link" href="/about">
            
            
              关于
            
          </a>
        </li>
      
    </ul>
  
</nav>

      </header>

      <main id="main" class="main">
        <div class="content-wrapper">
          <div id="content" class="content">
            
  
  <article class="post">
    <header class="post-header">
      <h1 class="post-title">
        
          Spark 调优 上
        
      </h1>

      <div class="post-meta">
        <span class="post-time">
          2019-03-22
        </span>
        
          <span class="post-category">
            
              <a href="/categories/Spark/">Spark</a>
            
              <a href="/categories/Spark/调优/">调优</a>
            
              <a href="/categories/Spark/调优/数据处理/">数据处理</a>
            
          </span>
        
        
      </div>
    </header>

    
    
  <div class="post-toc" id="post-toc">
    <h2 class="post-toc-title">文章目录</h2>
    <div class="post-toc-content">
      <ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#前言"><span class="toc-text">前言</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#Spark-如何执行程序"><span class="toc-text">Spark 如何执行程序</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#driver-和-executor-概述"><span class="toc-text">driver 和 executor 概述</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#job-stage-task"><span class="toc-text">job,stage,task</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#shuffle"><span class="toc-text">shuffle</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#选择正确的算子"><span class="toc-text">选择正确的算子</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#减少-shuffle-的数量"><span class="toc-text">减少 shuffle 的数量</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#广播变量"><span class="toc-text">广播变量</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#增加-Shuffle-的数量"><span class="toc-text">增加 Shuffle 的数量</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#二次排序"><span class="toc-text">二次排序</span></a></li></ol>
    </div>
  </div>



    <div class="post-content">
      
        <blockquote>
<p>本篇文章是在结合自己业务和<a href="https://blog.cloudera.com/blog/2015/03/how-to-tune-your-apache-spark-jobs-part-1/" target="_blank" rel="noopener">这篇文章</a>的基础上写的。</p>
</blockquote>
<h1 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h1><p>在编写和维护一个 Spark 程序的过程中，会遇到一些相关术语：</p>
<ul>
<li><p><code>transformation</code>, <code>action</code>, <code>RDD</code>, <code>DataSet</code>, <code>DataFrame</code></p>
<p>  理解这一层次的<em>原语</em>对于写出一个 Spark 很重要。因为一个 Spark 程序都是由这些结构和操作构成的。</p>
</li>
<li><p><code>job</code>, <code>stage</code>, <code>task</code></p>
<p>  如果想要<strong>写出一个好的 Spark 程序</strong>，理解这一层的原语就变得很重要。因为当你发现你的 Spark 程序运行得很慢或者报错了，你需要到 web UI 上查看原因，而这就是你需要理解这些术语的原因。</p>
</li>
</ul>
<p>总之，要写出一个高效的 Spark 程序，理解其底层运行模型是至关重要的。</p>
<a id="more"></a>
<h1 id="Spark-如何执行程序"><a href="#Spark-如何执行程序" class="headerlink" title="Spark 如何执行程序"></a>Spark 如何执行程序</h1><p>众所周知，一个 Spark 应用由一个 <code>driver</code> 进程和多个 <code>executor</code> 进程组成。这些进程都分散在一个集群的多个节点上。</p>
<h2 id="driver-和-executor-概述"><a href="#driver-和-executor-概述" class="headerlink" title="driver 和 executor 概述"></a><code>driver</code> 和 <code>executor</code> 概述</h2><p><code>driver</code> 负责从上层掌控所有工作的控制流；<br><code>executor</code> 负责以 <code>task</code> 的形式执行这些工作；除此之外，<code>executor</code> 还负责存储用户手动 <code>cache()</code> 的数据。</p>
<p><code>driver</code> 和 <code>executor</code> 在整个应用运行期间通常会保持不变。（1.3 以后可以用<a href="http://spark.apache.org/docs/1.2.0/job-scheduling.html#dynamic-resource-allocation" target="_blank" rel="noopener">动态资源分配</a>来动态管理）</p>
<p>每个 <code>executor</code> 都有一些 <code>slots</code> 用于运行 <code>tasks</code>：这些任务可以在这个 executor 的生命周期内并行地运行。</p>
<h2 id="job-stage-task"><a href="#job-stage-task" class="headerlink" title="job,stage,task"></a><code>job</code>,<code>stage</code>,<code>task</code></h2><center><img src="/images/spark_tuning/1553071574538.png" alt="Alt text"></center>

<p>如上图所示，在执行层次的最上层是 <code>jobs</code>:</p>
<p>在 Spark 应用内部调用一个 <code>action</code> 方法就会触发一个 Spark job 的启动。</p>
<p>Spark 通过检查这个 <code>action</code> 依赖的 <code>RDD</code> 的 DAG 并生成一个执行计划：</p>
<ul>
<li><p>这个执行计划从最远端的 RDD(指那些没有任何依赖其他 RDD 或者 已经 cache 过的 RDD 的 RDD) 开始，到最终的 RDD 。</p>
</li>
<li><p>这个执行计划还包括 <em>将 job 的 transformation 方法组装成 <code>stages</code></em>：</p>
<ul>
<li>每个 stage 对应到一组 <em>tasks</em>，<strong>这组 <code>task</code> 都执行相同的代码</strong>，只是每个 task 运行在不同的数据集上。</li>
<li>每个 stage 都包含一组无需 <em>shuffling</em> 过程的 transformation。</li>
</ul>
</li>
</ul>
<p>那么决定是否需要 <code>full shuffle</code> 的因素是什么呢？</p>
<p>每个 <code>RDD</code> 都由固定数量的分区组成，每个分区包含一部分数据记录。对于那些由 <code>narrow transformation</code> (比如 map, filter)返回的 <code>RDD</code>，每个分区中的数据只需要依赖父 RDD 的同一个分区，每个数据记录的产生只需要依赖父 RDD 中的一个记录。</p>
<blockquote>
<p>注意，<code>coalesce</code> 方法也被认为是 <code>narrow transformation</code>。因为该方法不涉及到 <code>full shuffle</code>，只会将某些分区的数据移动到另外分区上。详情可以参考 <a href="https://stackoverflow.com/questions/31610971/spark-repartition-vs-coalesce" target="_blank" rel="noopener">这个回答</a>和<a href="https://medium.com/@mrpowers/managing-spark-partitions-with-coalesce-and-repartition-4050c57ad5c4" target="_blank" rel="noopener">这个文章</a></p>
</blockquote>
<p>相对的，对于 <code>wide transformation</code> (比如 <code>groupByKey</code>, <code>reduceByKey</code>)，RDD 的一个分区的数据产生可能依赖父 RDD 的多个分区。</p>
<p>对于有 <code>key</code> 的 数据，同一个 key 对应的所有数据都必须落在相同的分区，由同一个 <code>task</code> 处理：</p>
<p>这就要求 Spark 必须执行一个 <code>shuffle</code> 操作，起一个新的 <code>stage</code>，将集群中所有相关的数据都放在一些新的分区中。 </p>
<p>举个例子：</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">val</span> tokenized = sc.textFile(args(<span class="number">0</span>)).flatMap(_.split(' '))</span><br><span class="line"><span class="keyword">val</span> wordCounts = tokenized.map((_, <span class="number">1</span>)).reduceByKey(_ + _)</span><br><span class="line"><span class="keyword">val</span> filtered = wordCounts.filter(_._2 &gt;= <span class="number">1000</span>)</span><br><span class="line"><span class="keyword">val</span> charCounts = filtered.flatMap(_._1.toCharArray).map((_, <span class="number">1</span>)).</span><br><span class="line">  reduceByKey(_ + _)</span><br><span class="line">charCounts.collect()</span><br></pre></td></tr></table></figure>
<p>上述代码会以 <code>reduceByKey</code> 为分界线产生 3 个 <code>stage</code>。</p>
<p>对于更为复杂一点的操作如：</p>
<center><img src="/images/spark_tuning/1553101691290.png" alt="Alt text"></center>

<p>每个洋红框都表示一个 stage。</p>
<h2 id="shuffle"><a href="#shuffle" class="headerlink" title="shuffle"></a>shuffle</h2><p>在每个 stage 的边界，数据都被 <strong>父 Stage</strong> 中的 task 写到磁盘上，并且由 <strong>子 Stage</strong> 中的 task 跨网络远程取走:</p>
<ul>
<li>由于涉及到 网络 IO 和 磁盘 IO，所以 Stage 边界这个事情非常昂贵，应该想方设法避免；</li>
<li>父子 Stage 中 RDD 的分区数量可能有所不同：只需要一个 <code>numPartitions</code> 参数就能让 <code>transformation</code> 触发一个 stage 边界并决定了子 Stage 的 RDD 分区数量。</li>
<li>Stage 边界的分区数量会很大程度上影响一个 Spark 应用的性能。</li>
</ul>
<h1 id="选择正确的算子"><a href="#选择正确的算子" class="headerlink" title="选择正确的算子"></a>选择正确的算子</h1><p>有时候使用不同的 <code>transformation</code> 和 <code>action</code> 算子可以得到相同的结果，但是不同的选择带来的开销可能会截然不同。</p>
<p>使用 <code>SparkSQL</code> 时可能不必考虑该如何挑选算子，但是使用 <code>DataSet</code> 或者 <code>RDD</code> 接口时，就需要仔细考虑了。</p>
<p><strong>选择算子的首要目的是<em>减少 shuffle 的次数</em></strong>：shuffle 的数据都要先写在磁盘并通过网络发送。</p>
<p><code>repartition</code>, <code>join</code>, <code>cogroup</code>, <code>*By</code>, <code>*ByKey</code> 等 transformation 算子都会造成数据 <code>shuffle</code>，常见的优化手段和注意事项：</p>
<ul>
<li><p><strong>在执行一个关联 reduce 操作时，避免使用 <code>groupByKey</code></strong>：<br>  比如，<code>rdd.groupByKey.mapValues(_.sum)</code> 和 <code>rdd.reduceByKey(_ + _)</code> 的结果相同，但是前者会在网络中移动整个数据集合，而后者<em>会先计算本地每个 key 对应 value 的和，然后再 shuffle，然后再计算总的和。</em></p>
</li>
<li><p><strong>当输入和输出值的类型不同时，使用 <code>aggregateByKey</code></strong><br>  <code>aggregateByKey</code> 使用 <code>map-side</code> 聚合</p>
</li>
<li><p><strong>不要使用 <code>flatMap-join-groupBy</code> 模式</strong><br>  当两个数据集已经根据 key 分好组，而想要 Join 并保持分组时，使用 <code>cogroup</code>，可以避免 解包和打包的开销。</p>
</li>
</ul>
<h1 id="减少-shuffle-的数量"><a href="#减少-shuffle-的数量" class="headerlink" title="减少 shuffle 的数量"></a>减少 <code>shuffle</code> 的数量</h1><p>当上一个 <code>transformation</code> 已经根据相同的 <code>partitioner</code> 将数据分区时，Spark 会避免 shuffle：</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">rdd1 = someRdd.reduceByKey(...)</span><br><span class="line">rdd2 = someOtherRdd.reduceByKey(...)</span><br><span class="line">rdd3 = rdd1.join(rdd2)</span><br></pre></td></tr></table></figure>
<p>由于没有 partitioner 被当做参数传进 <code>reduceByKey</code>，Spark 会使用默认 partitioner。</p>
<p>这两个 <code>reduceByKey</code> transformation 会造成两次 shuffle。</p>
<p>当两个 rdd 都被 <code>reduceByKey</code> 操作重新分为<strong>相同个数的分区</strong>时，<code>join</code> 算子就不会造成新的 shuffle：</p>
<p>这是因为在分区数相同时，RDD1 在同一个结果分区中的 keys 只可能出现在 RDD2 的一个分区中。因此 RDD3 的一个分区只依赖于 RDD1 的一个分区 和 RDD2 的一个分区，所以就没有第三个 shuffle：</p>
<center><img src="/images/spark_tuning/1553184746735.png" alt="Alt text"></center>

<p>当使用不同的 partitioner 时，只有 partitioner 较小的 rdd 需要 reshuffle:</p>
<center><img src="/images/spark_tuning/1553185011134.png" alt="Alt text"></center>


<h2 id="广播变量"><a href="#广播变量" class="headerlink" title="广播变量"></a>广播变量</h2><p>在 join 两个数据集时，还有一种方法可以避免 shuffle：<a href="https://spark.apache.org/docs/2.2.0/rdd-programming-guide.html#broadcast-variables" target="_blank" rel="noopener">广播变量</a>。</p>
<p>当其中一个数据集小到足以放进每个 executor 的内存中时，可以将其以 HashMap 的形式加载到 <code>driver</code> 的内存中，然后将其广播到每个 executor 的内存中。然后 join 操作就可以在每个 executor 中单独进行而不需要 shuffle 了。</p>
<h1 id="增加-Shuffle-的数量"><a href="#增加-Shuffle-的数量" class="headerlink" title="增加 Shuffle 的数量"></a>增加 Shuffle 的数量</h1><p>也有当 shuffle 次数增加时，性能更好的情况：</p>
<ul>
<li><p>当输入数据量很大，但是 <code>InputFormat</code> 给每个分区分配了数量巨大的数据时，使用 <code>repartition</code> 算子将分区增加可以让每个分区处理更少的数据，从而更好的利用集群中的 多核，从而提升系统的性能。</p>
</li>
<li><p>当需要将聚合后的数据发送到 <code>Driver</code> 时，先在每个分区使用 <code>reduceByKey</code> 或者 <code>aggregateByKey</code> 操作可以将计算的压力分散到多个分区上从而减小 <code>driver</code> 的计算量。 <strong>这种操作对那些已经根据 key 分好组的情况尤其有用!</strong></p>
</li>
</ul>
<h1 id="二次排序"><a href="#二次排序" class="headerlink" title="二次排序"></a>二次排序</h1><p><code>repartitionAndSortWithinPartitions</code> 将排序操作下推到 shuffle 的阶段，量大的数据可以被有效地分割，并且排序操作可以和其他操作结合在一起进行。</p>
<p>当你想要先将数据根据 key 分组后，在每个 key 对应的这组数据内根据某个字段排序时，可以直接用这个方法。</p>
<p>(To Be Continued…)</p>

      
    </div>

    
      
      



      
      
    

    
      <footer class="post-footer">
        
          <div class="post-tags">
            
              <a href="/tags/数据处理/">数据处理</a>
            
              <a href="/tags/Spark/">Spark</a>
            
              <a href="/tags/调优/">调优</a>
            
          </div>
        
        
        
  <nav class="post-nav">
    
      <a class="prev" href="/2019/03/23/tuning-spark-2/">
        <i class="iconfont icon-left"></i>
        <span class="prev-text nav-default">Spark 调优 下</span>
        <span class="prev-text nav-mobile">上一篇</span>
      </a>
    
    
      <a class="next" href="/2019/03/05/flink-learning-6/">
        <span class="next-text nav-default">Flink 学习笔记之六 外部读写</span>
        <span class="prev-text nav-mobile">下一篇</span>
        <i class="iconfont icon-right"></i>
      </a>
    
  </nav>


      </footer>
    

  </article>


          </div>
          
  <div class="comments" id="comments">
    
      <div id="vcomments"></div>
    
  </div>


        </div>
      </main>

      <footer id="footer" class="footer">

  <div class="social-links">
    
      
        
          <a href="mailto:pengye91@gmail.com" class="iconfont icon-email" title="email"></a>
        
      
    
      
    
      
    
      
    
      
    
      
    
      
        
          <a href="https://github.com/pengye91" class="iconfont icon-github" title="github"></a>
        
      
    
      
    
      
    
      
    
      
    
      
    
      
    

    
      
      <a href="/atom.xml" class="iconfont icon-rss" title="rss"></a>
    
  </div>



<div class="copyright">
  <span class="power-by">
    由 <a class="hexo-link" href="https://hexo.io/">Hexo</a> 强力驱动
  </span>
  <span class="division">|</span>
  <span class="theme-info">
    主题 - 
    <a class="theme-link" href="https://github.com/ahonn/hexo-theme-even">Even</a>
  </span>

  <span class="copyright-year">
    
    &copy; 
     
      2018 - 
    
    2020

    <span class="heart">
      <i class="iconfont icon-heart"></i>
    </span>
    <span class="author">xyp</span>
  </span>
</div>

      </footer>

      <div class="back-to-top" id="back-to-top">
        <i class="iconfont icon-up"></i>
      </div>
    </div>

    
  
  
<!-- valine Comments -->
<script src="//cdn1.lncld.net/static/js/3.0.4/av-min.js"></script>
<script src="//cdn.jsdelivr.net/gh/xcss/valine@v1.3.3/dist/Valine.min.js"></script>
<script type="text/javascript">
    new Valine({
        el: '#vcomments',
        notify: false,
        verify: false,
        visitor: true,
        app_id: "xeDhasO1xV7F1SpCG0oRuiol-gzGzoHsz",
        app_key: "wgFvo2YMOmn0Qcv7YPFxtePy",
        placeholder: "在此评论......",
        avatar: 'identicon'
    });
</script>


  

  



    
  



  
  





  
    <script type="text/javascript" src="/lib/jquery/jquery.min.js"></script>
  

  
    <script type="text/javascript" src="/lib/slideout/slideout.js"></script>
  

  
    <script type="text/javascript" src="/lib/fancybox/jquery.fancybox.pack.js"></script>
  

  
    <script type="text/javascript" src="/lib/pjax/jquery.pjax.min.js"></script>
  

  
    <script type="text/javascript" src="/lib/nprogress/nprogress.min.js"></script>
  


    <script type="text/javascript" src="/js/src/even.js?v=2.10.1"></script>

  </body>
</html>
